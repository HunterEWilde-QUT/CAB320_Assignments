{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea6071f-8e0f-4cfb-ae67-323337c91ba2",
   "metadata": {},
   "source": [
    "# CAB320 Assignment 2 - Transfer Learning\n",
    "Anthony Vanderkop, Thierry Peynot, Frederic Maire (Jupyter Notebook template: 2025)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69e9bb-1cf5-49cd-9cc5-8680461ea876",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "The functions and classes defined in this module will be called by the marker without modification. \n",
    "You should complete the functions and classes according to their specified interfaces.\n",
    "\n",
    "No partial marks will be awarded for functions that do not meet the specifications of the interfaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a200b943-94f5-4099-a330-1e2b89aaff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LIBRARY IMPORTS ###\n",
    "import os\n",
    "import numpy as np\n",
    "import keras.applications as ka\n",
    "import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2708ef2-ff27-4db9-8563-da2c648d69bd",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Implement the my_team()function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34388e34-bd90-4e02-9759-f7c4bd9a598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_team():\n",
    "    \"\"\"\n",
    "    Return the list of the team members of this assignment submission as a list\n",
    "    of triplet of the form (student_number, first_name, last_name)\n",
    "\n",
    "    \"\"\"\n",
    "    return [ (11032553, 'Hunter', 'Wilde'), (12026395, 'Oliver', 'Kele') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a005199c-572f-4968-9438-881ad28b62b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11032553, 'Hunter', 'Wilde'), (12026395, 'Oliver', 'Kele')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_team()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f05d766-c455-44f0-a0db-ae271e5926cf",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Download the small_flower_dataset from Canvas and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097372f-1af6-4295-b6c7-54eaa1558eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable to store class name to index mapping\n",
    "class_to_idx = {}\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load in the dataset from its home path. Path should be a string of the path\n",
    "    to the home directory the dataset is found in. Should return numpy arrays\n",
    "    with paired images and class labels.\n",
    "    \n",
    "    This function:\n",
    "    1. Loads images from the small_flower_dataset directory structure\n",
    "        - The dataset is organized with class folders, where folder name = class name\n",
    "    2. Organizes them into features (X) and labels (Y)\n",
    "    3. Returns tuple of (X, Y) where:\n",
    "       - X is a numpy array of images with shape (n_samples, height, width, channels)\n",
    "       - Y is a numpy array of integer labels with shape (n_samples,)\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    # Get the global variable class_to_idx\n",
    "    global class_to_idx\n",
    "    \n",
    "    # Get all subdirectories (class folders) in the path\n",
    "    class_dirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "    \n",
    "    # Clear the existing dictionary and assign new integer indices to each class\n",
    "    class_to_idx.clear()\n",
    "    for idx, class_name in enumerate(sorted(class_dirs)):\n",
    "        class_to_idx[class_name] = idx\n",
    "    \n",
    "    # Set target size for MobileNetV2 and to account for different image sizes in dataset\n",
    "    target_size = (224, 224)\n",
    "    \n",
    "    # Process each class directory\n",
    "    for class_name in class_dirs:\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        class_idx = class_to_idx[class_name]\n",
    "        \n",
    "        # Get all image files in the class directory\n",
    "        image_files = os.listdir(class_path)\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            # Load image and convert to array with target size of 224x224 (MobileNetV2 input size)\n",
    "            img = keras.utils.load_img(img_path, target_size=target_size)\n",
    "            img_array = keras.utils.img_to_array(img)\n",
    "            \n",
    "            # Add to dataset\n",
    "            X.append(img_array)\n",
    "            Y.append(class_idx)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    # Printf statements to check the dataset has been loaded correctly \n",
    "    print(f\"Dataset loaded: {X.shape[0]} images, {len(class_to_idx)} classes\")\n",
    "    print(f\"Image shape: {X.shape[1:]}\")\n",
    "    print(f\"Classes: {class_to_idx}\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c152ca73-ba01-4c86-9ae9-4080f48c005a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./small_flower_dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     46\u001b[39m img_path = os.path.join(class_path, img_file)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Load image and convert to array\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m img = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m img_array = keras.utils.img_to_array(img)\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Add to dataset\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olijk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:227\u001b[39m, in \u001b[36mload_img\u001b[39m\u001b[34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[32m    196\u001b[39m \n\u001b[32m    197\u001b[39m \u001b[33;03mExample:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    224\u001b[39m \u001b[33;03m    A PIL Image instance.\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    228\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import PIL.Image. The use of `load_img` requires PIL.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    229\u001b[39m     )\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, io.BytesIO):\n\u001b[32m    231\u001b[39m     img = pil_image.open(path)\n",
      "\u001b[31mImportError\u001b[39m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "dataset = load_data(\"./small_flower_dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80fac75b-cd93-43c5-8d8d-1879d7eca281",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Prepare your training, validation and test sets for the non-accelerated version of transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e860e1f6-3f93-4a43-9f1b-4cf4a41a3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, train_fraction, randomize=False, eval_set=True):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets. If eval_set is True, also create\n",
    "    an evaluation dataset. There should be two outputs if eval_set is False, or\n",
    "    three outputs (train, test, eval) if eval_set is True.\n",
    "    \n",
    "    This function performs stratified splitting to maintain class balance, ensuring\n",
    "    each split contains the same proportion of samples from each class.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.array\n",
    "        Array of image data with shape (n_samples, height, width, channels)\n",
    "    Y : numpy.array\n",
    "        Array of class labels with shape (n_samples,)\n",
    "    train_fraction : float\n",
    "        Fraction of data to use for training (between 0 and 1)\n",
    "    randomize : bool, optional\n",
    "        Whether to randomize the data before splitting (default: False)\n",
    "    eval_set : bool, optional\n",
    "        Whether to create a separate evaluation/validation set (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    If eval_set=True:\n",
    "        (train_set, eval_set, test_set) : tuple of tuples\n",
    "            Each inner tuple contains (images, labels) for the respective set\n",
    "    If eval_set=False:\n",
    "        (train_set, test_set) : tuple of tuples\n",
    "            Each inner tuple contains (images, labels) for the respective set\n",
    "    \"\"\"\n",
    "    # Get classes (known to be unique, but uses .unique() to catch any bugs/errors from earlier functions)\n",
    "    unique_classes = np.unique(Y)\n",
    "    \n",
    "    # Lists to store indices for each split\n",
    "    train_indices = []\n",
    "    eval_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # For each class, split its indices to maintain class balance\n",
    "    for class_idx in unique_classes:\n",
    "        # Get indices of samples belonging to this class\n",
    "        class_indices = np.flatnonzero(Y == class_idx)\n",
    "        num_samples = len(class_indices)\n",
    "        \n",
    "        # Randomize if requested\n",
    "        if randomize:\n",
    "            np.random.shuffle(class_indices)\n",
    "        \n",
    "        # Calculate split points\n",
    "        train_end = int(num_samples * train_fraction)\n",
    "        \n",
    "        if eval_set:\n",
    "            # Ensure equal sizes for validation and test sets\n",
    "            remaining = num_samples - train_end\n",
    "            val_samples = remaining // 2\n",
    "            \n",
    "            eval_end = train_end + val_samples\n",
    "            \n",
    "            # Add indices to respective sets\n",
    "            train_indices.extend(class_indices[:train_end].tolist())\n",
    "            eval_indices.extend(class_indices[train_end:eval_end].tolist())\n",
    "            test_indices.extend(class_indices[eval_end:].tolist())\n",
    "        else:\n",
    "            # No eval set, just train and test\n",
    "            train_indices.extend(class_indices[:train_end].tolist())\n",
    "            test_indices.extend(class_indices[train_end:].tolist())\n",
    "    \n",
    "    # Convert lists to integer numpy arrays explicitly\n",
    "    train_indices = np.array(train_indices, dtype=int)\n",
    "    test_indices = np.array(test_indices, dtype=int)\n",
    "    \n",
    "    # Create the final datasets\n",
    "    train_set = (X[train_indices], Y[train_indices])\n",
    "    test_set = (X[test_indices], Y[test_indices])\n",
    "    \n",
    "    if eval_set:\n",
    "        eval_indices = np.array(eval_indices, dtype=int)\n",
    "        eval_set_data = (X[eval_indices], Y[eval_indices])\n",
    "        \n",
    "        # Print statement for debugging/check\n",
    "        print(f\"Split complete: {len(train_indices)} train, {len(eval_indices)} validation, {len(test_indices)} test images\")\n",
    "        return train_set, eval_set_data, test_set\n",
    "    else:\n",
    "        # Print statement for debugging/check\n",
    "        print(f\"Split complete: {len(train_indices)} train, {len(test_indices)} test images\")\n",
    "        return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb930662-27e6-48ef-bb27-7a1416bc71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, eval_set, test_set = split_data(X, Y, train_fraction = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15589224-dd3f-4fad-ad8d-d15cfb802070",
   "metadata": {},
   "source": [
    "Report: Include details of how you have split the data to perform this training. Ensure the split is reasonable and does not introduce class imbalance during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde3a73-ca22-4a7f-9f80-3e967c101a9c",
   "metadata": {},
   "source": [
    "Insert details here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c32f044-7c28-4b05-88e4-1bb3c9a40e6a",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "Using the tf.keras.applications module download a pretrained MobileNetV2 network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030aa5ef-1c4b-4098-bcd7-8a04472b72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"\n",
    "    Load in a pretrained MobileNetV2 model using the keras.applications module.\n",
    "    \n",
    "    This function:\n",
    "    1. Downloads a pretrained MobileNetV2 network with weights from ImageNet\n",
    "    2. Sets up the model with the input shape appropriate for our dataset (224, 224, 3)\n",
    "    3. Ensures the base model layers are not trainable (frozen) for transfer learning\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : keras.Model\n",
    "        A pretrained MobileNetV2 model with frozen base layers, ready for transfer learning\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the pretrained model without the top classification layer\n",
    "    # Include weights from ImageNet, and use input shape of 224x224x3\n",
    "    base_model = ka.MobileNetV2(weights='imagenet', \n",
    "                            include_top=False, \n",
    "                            input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Freeze the layers in the base model so they won't be trained\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Print f statements to ensure model loaded correctly\n",
    "    print(f\"MobileNetV2 model loaded with {len(base_model.layers)} layers\")\n",
    "    print(f\"Input shape: {base_model.input_shape}\")\n",
    "    print(f\"Output shape: {base_model.output_shape}\")\n",
    "    \n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea297fc-1202-4a5c-b1ef-80ab85565d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad4169c-1a23-4861-a405-933e5e23acf2",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "Replace the last layer of the downloaded neural network with a Dense layer of the appropriate shape for the 5 classes of the small flower dataset {(x1,t1), (x2,t2),..., (xm,tm)}.\n",
    "\n",
    "## Task 6\n",
    "Compile and train your model with an SGD optimizer using the following parameters learning_rate=0.01, momentum=0.0, nesterov=False. (NB: The SGD class description can be found at https://keras.io/api/optimizers/sgd/  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772426f-bacc-4499-82b7-c39e7e6f759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_learning(train_set, eval_set, model, parameters):\n",
    "    \"\"\"\n",
    "    Implement and perform standard transfer learning here.\n",
    "\n",
    "    Inputs:\n",
    "        - train_set: list or tuple of the training images and labels in the\n",
    "            form (images, labels) for training the classifier\n",
    "        - eval_set: list or tuple of the images and labels used in evaluating\n",
    "            the model during training, in the form (images, labels)\n",
    "        - model: an instance of tf.keras.applications.MobileNetV2\n",
    "        - parameters: list or tuple of parameters to use during training:\n",
    "            (learning_rate, momentum, nesterov)\n",
    "\n",
    "\n",
    "    Outputs:\n",
    "        - model : an instance of tf.keras.applications.MobileNetV2\n",
    "\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa810f-fff8-444e-9bf7-ed363f5c1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = transfer_learning()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fb50fb9-d51c-44ce-bf19-0f9297e3e81f",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "Plot the training and validation errors and accuracies of standard transfer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db153942-2ebf-4dfa-81de-359e35f154e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9f737e-c8ae-45e5-9079-875df5bee670",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "Experiment with 3 different orders of magnitude for the learning rate. Plot the results and discuss in the below markdown cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae55c60-3f9b-490a-9bf6-8400991aed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab305b-8062-4109-83cc-27efa6da76d2",
   "metadata": {},
   "source": [
    "### Task 8 Analysis and discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0d640-a4f8-48d2-ab89-d67be0aa2ddb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0311fdb-24fd-4bec-8f92-57297187eccb",
   "metadata": {},
   "source": [
    "## Task 9\n",
    "Run the resulting classifier on your test dataset using results from the best learning rate you experimented with. Compute and display the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a466142-2557-4939-9e85-703c7848aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37409d3d-8d3d-46ae-ac6b-32f1e6024db1",
   "metadata": {},
   "source": [
    "## Task 10\n",
    "Compute the precision, recall, and f1 scores of your classifier on the test dataset using the best learning rate. Report on the results and comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91113bcb-87e7-4526-ba8b-21adddf0ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be01afb6-3d23-4c74-adc8-986d3990388c",
   "metadata": {},
   "source": [
    "## Task 11\n",
    "Perform k-fold validation on the dataset with k = 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b20cb7-76ca-4a56-9a41-707482122113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_validation(features, ground_truth, classifier, k=2):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        - features: np.ndarray of features in the dataset\n",
    "        - ground_truth: np.ndarray of class values associated with the features\n",
    "        - fit_func: f\n",
    "        - classifier: class object with both fit() and predict() methods which\n",
    "        can be applied to subsets of the features and ground_truth inputs.\n",
    "        - predict_func: function, calling predict_func(features) should return\n",
    "        a numpy array of class predictions which can in turn be input to the\n",
    "        functions in this script to calculate performance metrics.\n",
    "        - k: int, number of sub-sets to partition the data into. default is k=2\n",
    "    Outputs:\n",
    "        - avg_metrics: np.ndarray of shape (3, c) where c is the number of classes.\n",
    "        The first row is the average precision for each class over the k\n",
    "        validation steps. Second row is recall and third row is f1 score.\n",
    "        - sigma_metrics: np.ndarray, each value is the standard deviation of\n",
    "        the performance metrics [precision, recall, f1_score]\n",
    "    \"\"\"\n",
    "    \n",
    "    #split data\n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    #go through each partition and use it as a test set.\n",
    "    for partition_no in range(k):\n",
    "        #determine test and train sets\n",
    "        ### YOUR CODE HERE###\n",
    "        \n",
    "        #fit model to training data and perform predictions on the test set\n",
    "        classifier.fit(train_features, train_classes)\n",
    "        predictions = classifier.predict(test_features)\n",
    "        \n",
    "        #calculate performance metrics\n",
    "        ### YOUR CODE HERE###\n",
    "    \n",
    "    #perform statistical analyses on metrics\n",
    "    ### YOUR CODE HERE###\n",
    "    \n",
    "    raise NotImplementedError\n",
    "    return avg_metrics, sigma_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e8b614-53db-4adf-ae35-e96b0b0fa485",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code\n",
    "# xx = k_fold_validation(xx, xx, xx, xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201857c-0cd2-487b-a2ad-4e6abe619fbf",
   "metadata": {},
   "source": [
    "Comment on the results and any differences with the previous test-train split. \n",
    "Repeat with two different values for k and comment on the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16615b4-bbdd-445e-9835-34df03f3c8cb",
   "metadata": {},
   "source": [
    "### Comments and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1bae8a-30cc-4143-8de0-80477170caf6",
   "metadata": {},
   "source": [
    "## Task 12\n",
    "With the best learning rate that you found in the previous task, add a non-zero momentum to the training with the SGD optimizer (consider 3 values for the momentum). Report on how your results change.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44e49f-4adc-4d63-8bb3-15e39bb29e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5fa9c-94a3-4c7a-91a1-8d6afe9c4dce",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571260a-66e9-4b44-b012-74d7eee13359",
   "metadata": {},
   "source": [
    "## Task 13\n",
    "Now using “accelerated transfer learning”, repeat the training process (k-fold validation is optional this time). You should prepare your training, validation and test sets based on {(F(x1).t1), (F(x2),t2),...,(F(xm),tm)}, and re-do Task 12. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefd040-d00d-4869-8c96-67b5934d05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accelerated_learning(train_set, eval_set, model, parameters):\n",
    "    \"\"\"\n",
    "    Implement and perform accelerated transfer learning here.\n",
    "\n",
    "    Inputs:\n",
    "        - train_set: list or tuple of the training images and labels in the\n",
    "            form (images, labels) for training the classifier\n",
    "        - eval_set: list or tuple of the images and labels used in evaluating\n",
    "            the model during training, in the form (images, labels)\n",
    "        - model: an instance of tf.keras.applications.MobileNetV2\n",
    "        - parameters: list or tuple of parameters to use during training:\n",
    "            (learning_rate, momentum, nesterov)\n",
    "\n",
    "\n",
    "    Outputs:\n",
    "        - model : an instance of tf.keras.applications.MobileNetV2\n",
    "\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338442d-a821-40c1-9b65-2fed7e552da2",
   "metadata": {},
   "source": [
    "\n",
    "Plot and comment on the results and differences against the standard implementation of transfer learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0b0f6-99fc-4c28-bc2e-b8e0954279b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25897cb9-3a50-448a-98a0-d75b7cebe769",
   "metadata": {},
   "source": [
    "### Your Comments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c39cbe5-1894-4083-b8be-81b00b8822a4",
   "metadata": {},
   "source": [
    "## Task 14\n",
    "Use the results of all experiments to make suggestions for future work and recommendations for parameter values to anyone else who may be interested in a similar implementation of transfer learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d30537-a23b-4678-9336-a08a5c61e14f",
   "metadata": {},
   "source": [
    "### Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0218070e-f721-44d4-9efa-6b7004af906a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
