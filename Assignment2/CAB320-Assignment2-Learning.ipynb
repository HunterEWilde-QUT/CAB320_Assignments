{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea6071f-8e0f-4cfb-ae67-323337c91ba2",
   "metadata": {},
   "source": [
    "# CAB320 Assignment 2 - Transfer Learning\n",
    "Anthony Vanderkop, Thierry Peynot, Frederic Maire (Jupyter Notebook template: 2025)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69e9bb-1cf5-49cd-9cc5-8680461ea876",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "The functions and classes defined in this module will be called by the marker without modification. \n",
    "You should complete the functions and classes according to their specified interfaces.\n",
    "\n",
    "No partial marks will be awarded for functions that do not meet the specifications of the interfaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a200b943-94f5-4099-a330-1e2b89aaff27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T03:37:23.034377Z",
     "start_time": "2025-05-20T03:37:22.688202Z"
    }
   },
   "source": [
    "### LIBRARY IMPORTS ###\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.applications as ka\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapplications\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mka\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mplt\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\__init__.py:7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _tf_keras \u001B[38;5;28;01mas\u001B[39;00m _tf_keras\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m activations \u001B[38;5;28;01mas\u001B[39;00m activations\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m applications \u001B[38;5;28;01mas\u001B[39;00m applications\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\_tf_keras\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tf_keras\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m keras\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\_tf_keras\\keras\\__init__.py:7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m activations \u001B[38;5;28;01mas\u001B[39;00m activations\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m applications \u001B[38;5;28;01mas\u001B[39;00m applications\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m callbacks \u001B[38;5;28;01mas\u001B[39;00m callbacks\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\activations\\__init__.py:7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m deserialize \u001B[38;5;28;01mas\u001B[39;00m deserialize\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get \u001B[38;5;28;01mas\u001B[39;00m get\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m serialize \u001B[38;5;28;01mas\u001B[39;00m serialize\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m activations\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m backend\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\activations\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtypes\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m celu\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m elu\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m exponential\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\activations\\activations.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ops\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m keras_export\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\__init__.py:10\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m result_type\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras_tensor\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m KerasTensor\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras_tensor\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m any_symbolic_tensors\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\common\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m backend_utils\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m result_type\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutocastScope\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Variable \u001B[38;5;28;01mas\u001B[39;00m KerasVariable\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\common\\dtypes.py:5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m standardize_dtype\n\u001B[0;32m      7\u001B[0m BOOL_TYPES \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbool\u001B[39m\u001B[38;5;124m\"\u001B[39m,)\n\u001B[0;32m      8\u001B[0m INT_TYPES \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint8\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint16\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mint64\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\common\\variables.py:12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstateless_scope\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m in_stateless_scope\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tensorflow \u001B[38;5;28;01mas\u001B[39;00m tf\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnaming\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m auto_name\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mVariable\u001B[39;00m:\n\u001B[0;32m     16\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Represents a backend-agnostic variable in Keras.\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \n\u001B[0;32m     18\u001B[0m \u001B[38;5;124;03m    A `Variable` acts as a container for state. It holds a tensor value and can\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;124;03m    ```\u001B[39;00m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio_dataset_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m audio_dataset_from_directory\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m split_dataset\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfile_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_file\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\audio_dataset_utils.py:4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dataset_utils\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tensorflow \u001B[38;5;28;01mas\u001B[39;00m tf\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tensorflow_io \u001B[38;5;28;01mas\u001B[39;00m tfio\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\dataset_utils.py:9\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmultiprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpool\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ThreadPool\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tree\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m io_utils\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\tree\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m assert_same_paths\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m assert_same_structure\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m flatten\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\tree\\tree_api.py:8\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m optree\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optree\u001B[38;5;241m.\u001B[39mavailable:\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m optree_impl \u001B[38;5;28;01mas\u001B[39;00m tree_impl\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m dmtree\u001B[38;5;241m.\u001B[39mavailable:\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dmtree_impl \u001B[38;5;28;01mas\u001B[39;00m tree_impl\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\tree\\optree_impl.py:13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Register backend-specific node classes\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 13\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrackable\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_structures\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ListWrapper\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrackable\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_structures\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _DictWrapper\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2708ef2-ff27-4db9-8563-da2c648d69bd",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Implement the my_team()function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34388e34-bd90-4e02-9759-f7c4bd9a598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_team():\n",
    "    \"\"\"\n",
    "    Return the list of the team members of this assignment submission as a list\n",
    "    of triplet of the form (student_number, first_name, last_name)\n",
    "\n",
    "    \"\"\"\n",
    "    return [ (11032553, 'Hunter', 'Wilde'), (12026395, 'Oliver', 'Kele') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a005199c-572f-4968-9438-881ad28b62b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11032553, 'Hunter', 'Wilde'), (12026395, 'Oliver', 'Kele')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_team()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f05d766-c455-44f0-a0db-ae271e5926cf",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Download the small_flower_dataset from Canvas and load the data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Global variable to store class name to index mapping\n",
    "class_to_idx = {}\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load in the dataset from its home path. Path should be a string of the path\n",
    "    to the home directory the dataset is found in. Should return numpy arrays\n",
    "    with paired images and class labels.\n",
    "\n",
    "    This function:\n",
    "    1. Loads images from the small_flower_dataset directory structure\n",
    "        - The dataset is organized with class folders, where folder name = class name\n",
    "    2. Organizes them into features (X) and labels (Y)\n",
    "    3. Returns tuple of (X, Y) where:\n",
    "       - X is a numpy array of images with shape (n_samples, height, width, channels)\n",
    "       - Y is a numpy array of integer labels with shape (n_samples,)\n",
    "    \"\"\"\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    # Get the global variable class_to_idx\n",
    "    global class_to_idx\n",
    "\n",
    "    # Get all subdirectories (class folders) in the path\n",
    "    class_dirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "\n",
    "    # Clear the existing dictionary and assign new integer indices to each class\n",
    "    class_to_idx.clear()\n",
    "    for idx, class_name in enumerate(sorted(class_dirs)):\n",
    "        class_to_idx[class_name] = idx\n",
    "\n",
    "    # Set target size for MobileNetV2 and to account for different image sizes in dataset\n",
    "    target_size = (224, 224)\n",
    "\n",
    "    # Process each class directory\n",
    "    for class_name in class_dirs:\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        class_idx = class_to_idx[class_name]\n",
    "\n",
    "        # Get all image files in the class directory\n",
    "        image_files = os.listdir(class_path)\n",
    "\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "\n",
    "            # Load image and convert to array with target size of 224x224 (MobileNetV2 input size)\n",
    "            img = keras.utils.load_img(img_path, target_size=target_size)\n",
    "            img_array = keras.utils.img_to_array(img)\n",
    "\n",
    "            # Add to dataset\n",
    "            X.append(img_array)\n",
    "            Y.append(class_idx)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    # Printf statements to check the dataset has been loaded correctly \n",
    "    print(f\"Dataset loaded: {X.shape[0]} images, {len(class_to_idx)} classes\")\n",
    "    print(f\"Image shape: {X.shape[1:]}\")\n",
    "    print(f\"Classes: {class_to_idx}\")\n",
    "\n",
    "    return X, Y"
   ],
   "id": "82076152cfc036dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = load_data(\"./small_flower_dataset\")",
   "id": "6d655e0a54ffe32e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 3\n",
    "Prepare your training, validation and test sets for the non-accelerated version of transfer learning."
   ],
   "id": "1e56394ba276d68d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def split_data(X, Y, train_fraction, randomize=False, eval_set=True):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets. If eval_set is True, also create\n",
    "    an evaluation dataset. There should be two outputs if eval_set is False, or\n",
    "    three outputs (train, test, eval) if eval_set is True.\n",
    "\n",
    "    This function performs stratified splitting to maintain class balance, ensuring\n",
    "    each split contains the same proportion of samples from each class.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.array\n",
    "        Array of image data with shape (n_samples, height, width, channels)\n",
    "    Y : numpy.array\n",
    "        Array of class labels with shape (n_samples)\n",
    "    train_fraction : float\n",
    "        Fraction of data to use for training (between 0 and 1)\n",
    "    randomize : bool, optional\n",
    "        Whether to randomize the data before splitting (default: False)\n",
    "    eval_set : bool, optional\n",
    "        Whether to create a separate evaluation/validation set (default: True)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    If eval_set=True:\n",
    "        (train_set, eval_set, test_set) : tuple of tuples\n",
    "            Each inner tuple contains (images, labels) for the respective set\n",
    "    If eval_set=False:\n",
    "        (train_set, test_set) : tuple of tuples\n",
    "            Each inner tuple contains (images, labels) for the respective set\n",
    "    \"\"\"\n",
    "    # Get classes (known to be unique, but uses .unique() to catch any bugs/errors from earlier functions)\n",
    "    unique_classes = np.unique(Y)\n",
    "\n",
    "    # Lists to store indices for each split\n",
    "    train_indices = []\n",
    "    eval_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    # For each class, split its indices to maintain class balance\n",
    "    for class_idx in unique_classes:\n",
    "        # Get indices of samples belonging to this class\n",
    "        class_indices = np.flatnonzero(Y == class_idx)\n",
    "        num_samples = len(class_indices)\n",
    "\n",
    "        # Randomize if requested\n",
    "        if randomize:\n",
    "            np.random.shuffle(class_indices)\n",
    "\n",
    "        # Calculate split points\n",
    "        train_end = int(num_samples * train_fraction)\n",
    "\n",
    "        if eval_set:\n",
    "            # Ensure equal sizes for validation and test sets\n",
    "            remaining = num_samples - train_end\n",
    "            val_samples = remaining // 2\n",
    "\n",
    "            eval_end = train_end + val_samples\n",
    "\n",
    "            # Add indices to respective sets\n",
    "            train_indices.extend(class_indices[:train_end].tolist())\n",
    "            eval_indices.extend(class_indices[train_end:eval_end].tolist())\n",
    "            test_indices.extend(class_indices[eval_end:].tolist())\n",
    "        else:\n",
    "            # No eval set, just train and test\n",
    "            train_indices.extend(class_indices[:train_end].tolist())\n",
    "            test_indices.extend(class_indices[train_end:].tolist())\n",
    "\n",
    "    # Convert lists to integer numpy arrays explicitly\n",
    "    train_indices = np.array(train_indices, dtype=int)\n",
    "    test_indices = np.array(test_indices, dtype=int)\n",
    "\n",
    "    # Create the final datasets\n",
    "    train_set = (X[train_indices], Y[train_indices])\n",
    "    test_set = (X[test_indices], Y[test_indices])\n",
    "\n",
    "    if eval_set:\n",
    "        eval_indices = np.array(eval_indices, dtype=int)\n",
    "        eval_set_data = (X[eval_indices], Y[eval_indices])\n",
    "\n",
    "        # Print statement for debugging/check\n",
    "        print(f\"Split complete: {len(train_indices)} train, {len(eval_indices)} validation, {len(test_indices)} test images\")\n",
    "        return train_set, eval_set_data, test_set\n",
    "    else:\n",
    "        # Print statement for debugging/check\n",
    "        print(f\"Split complete: {len(train_indices)} train, {len(test_indices)} test images\")\n",
    "        return train_set, test_set"
   ],
   "id": "cbd853a0b0d3d0b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_set, eval_set, test_set = split_data(X, Y, train_fraction = 0.8)",
   "id": "82c93bac5b458a90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Report: Include details of how you have split the data to perform this training. Ensure the split is reasonable and does not introduce class imbalance during training",
   "id": "81eff9d2469b0706"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The array of class labels `Y` is first passed through a function which extracts only unique entries to ensure there are no repeated classes; the filtered class array `unique_classes` is then iterated over as each entry in `Y` is assigned to a unique class, resulting in a local instance of `class_indices` for each unique class, which contains all entries of that class (should be 1, excepting anomalies). The set of classes is split between the arrays `train_set` & `test_set` according to the ratio assigned to `train_fraction`.",
   "id": "130f8c6b5abc4272"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 4\n",
    "Using the tf.keras.applications module download a pretrained MobileNetV2 network. "
   ],
   "id": "5fb9287caecb3579"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T03:55:39.350151Z",
     "start_time": "2025-05-20T03:55:39.338230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model():\n",
    "    \"\"\"\n",
    "    Load in a pretrained MobileNetV2 model using the keras.applications module.\n",
    "\n",
    "    This function:\n",
    "    1. Downloads a pretrained MobileNetV2 network with weights from ImageNet\n",
    "    2. Sets up the model with the input shape appropriate for our dataset (224, 224, 3)\n",
    "    3. Ensures the base model layers are not trainable (frozen) for transfer learning\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model : keras.Model\n",
    "        A pretrained MobileNetV2 model with frozen base layers, ready for transfer learning\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pretrained model without the top classification layer\n",
    "    # Include weights from ImageNet, and use input shape of 224x224x3\n",
    "    base_model = ka.MobileNetV2(weights='imagenet', \n",
    "                            include_top=False, \n",
    "                            input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the layers in the base model so they won't be trained\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Print f statements to ensure model loaded correctly\n",
    "    print(f\"MobileNetV2 model loaded with {len(base_model.layers)} layers\")\n",
    "    print(f\"Input shape: {base_model.input_shape}\")\n",
    "    print(f\"Output shape: {base_model.output_shape}\")\n",
    "\n",
    "    return base_model"
   ],
   "id": "2f0fa379625b6b7e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T03:55:41.250449Z",
     "start_time": "2025-05-20T03:55:41.215508Z"
    }
   },
   "cell_type": "code",
   "source": "model = load_model()",
   "id": "735dd2ea9bc5f744",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ka' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[11], line 18\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mLoad in a pretrained MobileNetV2 model using the keras.applications module.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;124;03m    A pretrained MobileNetV2 model with frozen base layers, ready for transfer learning\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Load the pretrained model without the top classification layer\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Include weights from ImageNet, and use input shape of 224x224x3\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m base_model \u001B[38;5;241m=\u001B[39m \u001B[43mka\u001B[49m\u001B[38;5;241m.\u001B[39mMobileNetV2(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimagenet\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[0;32m     19\u001B[0m                         include_top\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \n\u001B[0;32m     20\u001B[0m                         input_shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m3\u001B[39m))\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Freeze the layers in the base model so they won't be trained\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m base_model\u001B[38;5;241m.\u001B[39mlayers:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'ka' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 5\n",
    "Replace the last layer of the downloaded neural network with a Dense layer of the appropriate shape for the 5 classes of the small flower dataset {(x1,t1), (x2,t2),..., (xm,tm)}.\n",
    "\n",
    "## Task 6\n",
    "Compile and train your model with an SGD optimizer using the following parameters learning_rate=0.01, momentum=0.0, nesterov=False. (NB: The SGD class description can be found at https://keras.io/api/optimizers/sgd/  )"
   ],
   "id": "1c99f0eab0f10e65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T03:55:26.964986Z",
     "start_time": "2025-05-20T03:55:26.947058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transfer_learning(train_set, eval_set, model, parameters=(0.01, 0.0, False)):\n",
    "    \"\"\"\n",
    "    Implement and perform standard transfer learning here.\n",
    "\n",
    "    Inputs:\n",
    "        - train_set: list or tuple of the training images and labels in the\n",
    "            form (images, labels) for training the classifier\n",
    "        - eval_set: list or tuple of the images and labels used in evaluating\n",
    "            the model during training, in the form (images, labels)\n",
    "        - model: an instance of tf.keras.applications.MobileNetV2\n",
    "        - parameters: tuple of parameters to use during training:\n",
    "            (learning_rate, momentum, nesterov)\n",
    "\n",
    "    Outputs:\n",
    "        - model : an instance of tf.keras.applications.MobileNetV2\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack parameters\n",
    "    learning_rate, momentum, nesterov = parameters\n",
    "\n",
    "    # Unpack datasets\n",
    "    x_train, y_train = train_set\n",
    "    x_eval, y_eval = eval_set\n",
    "\n",
    "    # Get number of classes from the dataset\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    # Add a global average pooling layer and a new classification layer\n",
    "    x = model.output\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    predictions = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the final model\n",
    "    final_model = keras.models.Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "    # Compile the model with specified parameters\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum, nesterov=nesterov)\n",
    "    final_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',  # Use for integer class labels\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Define callbacks for training\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.keras\",\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,  # Number of epochs with no improvement after which to stop\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = final_model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_eval, y_eval),\n",
    "        epochs=50,  # Can be adjusted\n",
    "        batch_size=32,  # Can be adjusted\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Store the training history as an attribute for later analysis\n",
    "    final_model.history = history\n",
    "\n",
    "    return final_model"
   ],
   "id": "3495fbabef5617b2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T03:55:30.203356Z",
     "start_time": "2025-05-20T03:55:30.174516Z"
    }
   },
   "cell_type": "code",
   "source": "model = transfer_learning(train_set, eval_set, model)",
   "id": "e24a2b4a1de427cc",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m transfer_learning(\u001B[43mtrain_set\u001B[49m, eval_set, model)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Report: Provide an overview of the function and how it works.",
   "id": "ed618238f139d0f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After first unpacking all necessary data from the input parameters, two new layers (a GAP layer & a softmax classification layer) are added to the model, which are derived from the output of the model's previous version. The new model is compiled, reusing the input parameters given for the previous model. Checkpoints & early stopping points are defined for time-saving during training. Finally, the previous version of the model is appended to the model history.",
   "id": "5b5d16b37e0fa58a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 7\n",
    "Plot the training and validation errors and accuracies of standard transfer "
   ],
   "id": "3c90419b8a88c5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T03:54:40.269284Z",
     "start_time": "2025-05-20T03:54:40.261779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_errors(model):\n",
    "    \"\"\"\n",
    "    Plot the training & validation errors & accuracies from the model's training history.\n",
    "\n",
    "    This function:\n",
    "    1. Creates two subplots: one for error & one for accuracy.\n",
    "    2. Plots both training & validation metrics on each subplot.\n",
    "    3. Adds appropriate labels, titles, & legend.\n",
    "    \"\"\"\n",
    "    # Get the number of epochs\n",
    "    epochs = range(1, len(model.history['loss']) + 1)\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Plot training & validation error\n",
    "    ax1.plot(epochs, model.history['loss'], 'b-', label='Training Loss')\n",
    "    ax1.plot(epochs, model.history['val_loss'], 'r-', label='Validation Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Plot training & validation accuracies\n",
    "    ax2.plot(epochs, model.history['accuracy'], 'b-', label='Training Accuracy')\n",
    "    ax2.plot(epochs, model.history['val_accuracy'], 'r-', label='Validation Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "3f7bf63d74eb8ab9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T03:55:11.282493Z",
     "start_time": "2025-05-20T03:55:11.248426Z"
    }
   },
   "cell_type": "code",
   "source": "plot_errors(model)",
   "id": "aa76dccddd01d0b8",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Call the plot_errors function to visualize training and validation metrics\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mplot_errors\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[7], line 12\u001B[0m, in \u001B[0;36mplot_errors\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mPlot the training and validation errors (loss) and accuracies from the model's training history.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;03m4. Adds appropriate labels, titles, and legend\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Get the number of epochs\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Create a figure with two subplots\u001B[39;00m\n\u001B[0;32m     15\u001B[0m fig, (ax1, ax2) \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplots(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m5\u001B[39m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 8\n",
    "Experiment with 3 different orders of magnitude for the learning rate. Plot the results and discuss in the below markdown cell"
   ],
   "id": "9aa6f483a451d5d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Your code",
   "id": "d6961fc5190ae971"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Task 8 Analysis and discussion\n",
   "id": "c237ebbde24d4f0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "721ff5d2cb40a565"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 9\n",
    "Run the resulting classifier on your test dataset using results from the best learning rate you experimented with. Compute and display the confusion matrix. "
   ],
   "id": "2c1bd24e5cb52a47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Your code",
   "id": "f164967c952860a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 10\n",
    "Compute the precision, recall, and f1 scores of your classifier on the test dataset using the best learning rate. Report on the results and comment. "
   ],
   "id": "c1a7e4f98ac0c5da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Your code",
   "id": "f90e20a483277e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 11\n",
    "Perform k-fold validation on the dataset with k = 3. "
   ],
   "id": "5d33ab6385b3dd3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def k_fold_validation(features, ground_truth, classifier, k=2):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        - features: np.ndarray of features in the dataset\n",
    "        - ground_truth: np.ndarray of class values associated with the features\n",
    "        - fit_func: f\n",
    "        - classifier: class object with both fit() and predict() methods which\n",
    "        can be applied to subsets of the features and ground_truth inputs.\n",
    "        - predict_func: function, calling predict_func(features) should return\n",
    "        a numpy array of class predictions which can in turn be input to the\n",
    "        functions in this script to calculate performance metrics.\n",
    "        - k: int, number of sub-sets to partition the data into. default is k=2\n",
    "    Outputs:\n",
    "        - avg_metrics: np.ndarray of shape (3, c) where c is the number of classes.\n",
    "        The first row is the average precision for each class over the k\n",
    "        validation steps. Second row is recall and third row is f1 score.\n",
    "        - sigma_metrics: np.ndarray, each value is the standard deviation of\n",
    "        the performance metrics [precision, recall, f1_score]\n",
    "    \"\"\"\n",
    "\n",
    "    #split data\n",
    "    ### YOUR CODE HERE ###\n",
    "\n",
    "    #go through each partition and use it as a test set.\n",
    "    for partition_no in range(k):\n",
    "        #determine test and train sets\n",
    "        ### YOUR CODE HERE###\n",
    "\n",
    "        #fit model to training data and perform predictions on the test set\n",
    "        classifier.fit(train_features, train_classes)\n",
    "        predictions = classifier.predict(test_features)\n",
    "\n",
    "        #calculate performance metrics\n",
    "        ### YOUR CODE HERE###\n",
    "\n",
    "    #perform statistical analyses on metrics\n",
    "    ### YOUR CODE HERE###\n",
    "\n",
    "    raise NotImplementedError\n",
    "    return avg_metrics, sigma_metrics"
   ],
   "id": "89965176c910f515"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e8b614-53db-4adf-ae35-e96b0b0fa485",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code\n",
    "# xx = k_fold_validation(xx, xx, xx, xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201857c-0cd2-487b-a2ad-4e6abe619fbf",
   "metadata": {},
   "source": [
    "Comment on the results and any differences with the previous test-train split. \n",
    "Repeat with two different values for k and comment on the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16615b4-bbdd-445e-9835-34df03f3c8cb",
   "metadata": {},
   "source": [
    "### Comments and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1bae8a-30cc-4143-8de0-80477170caf6",
   "metadata": {},
   "source": [
    "## Task 12\n",
    "With the best learning rate that you found in the previous task, add a non-zero momentum to the training with the SGD optimizer (consider 3 values for the momentum). Report on how your results change.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44e49f-4adc-4d63-8bb3-15e39bb29e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5fa9c-94a3-4c7a-91a1-8d6afe9c4dce",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571260a-66e9-4b44-b012-74d7eee13359",
   "metadata": {},
   "source": [
    "## Task 13\n",
    "Now using “accelerated transfer learning”, repeat the training process (k-fold validation is optional this time). You should prepare your training, validation and test sets based on {(F(x1).t1), (F(x2),t2),...,(F(xm),tm)}, and re-do Task 12. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefd040-d00d-4869-8c96-67b5934d05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accelerated_learning(train_set, eval_set, model, parameters):\n",
    "    \"\"\"\n",
    "    Implement and perform accelerated transfer learning here.\n",
    "\n",
    "    Inputs:\n",
    "        - train_set: list or tuple of the training images and labels in the\n",
    "            form (images, labels) for training the classifier\n",
    "        - eval_set: list or tuple of the images and labels used in evaluating\n",
    "            the model during training, in the form (images, labels)\n",
    "        - model: an instance of tf.keras.applications.MobileNetV2\n",
    "        - parameters: list or tuple of parameters to use during training:\n",
    "            (learning_rate, momentum, nesterov)\n",
    "\n",
    "\n",
    "    Outputs:\n",
    "        - model : an instance of tf.keras.applications.MobileNetV2\n",
    "\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338442d-a821-40c1-9b65-2fed7e552da2",
   "metadata": {},
   "source": [
    "\n",
    "Plot and comment on the results and differences against the standard implementation of transfer learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0b0f6-99fc-4c28-bc2e-b8e0954279b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25897cb9-3a50-448a-98a0-d75b7cebe769",
   "metadata": {},
   "source": [
    "### Your Comments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c39cbe5-1894-4083-b8be-81b00b8822a4",
   "metadata": {},
   "source": [
    "## Task 14\n",
    "Use the results of all experiments to make suggestions for future work and recommendations for parameter values to anyone else who may be interested in a similar implementation of transfer learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d30537-a23b-4678-9336-a08a5c61e14f",
   "metadata": {},
   "source": [
    "### Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0218070e-f721-44d4-9efa-6b7004af906a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
